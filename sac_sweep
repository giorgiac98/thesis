command:
  - ${env}
  - ${interpreter}
  - train.py
  - model=sac
  - ${args_no_hyphens}
method: bayes
metric:
  name: eval/episode_reward
  goal: maximize
parameters:
  collector.collector.frames_per_batch:
    distribution: int_uniform
    max: 9600
    min: 630
  collector.num_envs:
    distribution: categorical
    values:
      - 2
      - 4
      - 8
      - 16
  model.policy_spec.num_qvalue_nets:
    distribution: categorical
    values:
      - 2
      - 3
  model.actor_net_spec.num_cells:
    distribution: categorical
    values:
      - 8
      - 16
      - 32
      - 64
  model.value_net_spec.num_cells:
    distribution: categorical
    values:
      - 8
      - 16
      - 32
      - 64
  model.other_spec.init_random_frames:
    distribution: int_uniform
    max: 2000
    min: 200
  model.other_spec.target_update_polyak:
    distribution: categorical
    values:
      - 0.005
      - 0.001
      - 0.01
  update_rounds:
    distribution: categorical
    values:
      - 4
      - 8
      - 12
  batch_size:
    distribution: categorical
    values:
      - 32
      - 64
      - 128
      - 256
      - 512
  lr:
    distribution: categorical
    values:
      - 0.01
      - 0.005
      - 0.0025
      - 0.001
      - 0.0005

